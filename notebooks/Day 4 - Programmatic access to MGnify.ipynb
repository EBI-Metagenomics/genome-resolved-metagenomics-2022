{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1eea88-aefd-46e6-8e95-1a6da6bdeef3",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1200px\"><img src=\"assets/mgnify_banner.png\" width=\"100%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2829d-7fb4-42c5-b27c-96327645128a",
   "metadata": {},
   "source": [
    "<img src=\"assets/mgnify_logo.png\" width=\"200px\">\n",
    "\n",
    "# Genome-resolved metagenomics bioinformatics 2022\n",
    "\n",
    "## Programmatic access to MGnify resources with APIs and notebooks (practical session)\n",
    "\n",
    "The [MGnify API](https://www.ebi.ac.uk/metagenomics/api/v1/) (Application Programming Interface) is a service to get data from MGnify using command line tools, scripts, code notebooks, etc.\n",
    "It can be access from pretty much any coding language... but Python and R are the most popular choices.\n",
    "\n",
    "### Today we will use Python\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\" width=\"120px\">\n",
    "\n",
    "You don't need to know Python to do this — all of the answers are given.\n",
    "\n",
    "### Tomorrow we will use R\n",
    "<img src=\"https://www.r-project.org/logo/Rlogo.png\" width=\"60px\">\n",
    "\n",
    "You won't need to know R either – and there is a helper library called [MGnifyR](http://github.com/beadyallen/mgnifyr) that you'll learn to use tomorrow.\n",
    "\n",
    "**This is an interactive code notebook (a Jupyter Notebook). To run this code, click into each cell and press the ▶ button in the top toolbar, or press `shift + enter`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea10f7d-50d8-4e37-b123-a910b3782afd",
   "metadata": {},
   "source": [
    "---\n",
    "# Core concepts\n",
    "An [API](https://en.wikipedia.org/wiki/API \"Application programming interface\") is how your scripts (e.g. Python or R) can talk to the MGnify database.\n",
    "\n",
    "The MGnify API uses [JSON](https://en.wikipedia.org/wiki/JSON \"Javascript Object Notation\") to transfer data in a systematic way. This is human-readable and computer-readable.\n",
    "\n",
    "The particular format we use is a standard called [JSON:API](https://jsonapi.org). \n",
    "There is a Python package ([`jsonapi_client`](https://pypi.org/project/jsonapi-client/)) to make consuming this data easy. We're using it here.\n",
    "\n",
    "The MGnify API has a \"browsable interface\", which is a human-friendly way of exploring the API. The URLs for the browsable API are exactly the same as you'd use in a script or code; but when you open those URLs in a browser you see a nice interface. Find it here: [https://www.ebi.ac.uk/metagenomics/api/v1/](https://www.ebi.ac.uk/metagenomics/api/v1/).\n",
    "\n",
    "The MGnify API is \"paginated\", i.e. when you list some data you are given it in multiple pages. This is because there can sometimes by thousands of results. Thankfully `jsonapi_client` handles this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f67e4-35cb-4253-bb95-4f2d0485c363",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54652c-dcc6-4fc2-bb59-91ea66ae5730",
   "metadata": {
    "tags": []
   },
   "source": [
    "[pandas](https://pandas.pydata.org/docs/reference/index.html#api) is a data analysis library with a huge list of features. It is very good at holding and manipulating table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8f45a-7bed-4f4b-a964-7813543e76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199dc17-0761-4456-ae48-b9341a510e7f",
   "metadata": {},
   "source": [
    "[jsonapi-client](https://pypi.org/project/jsonapi-client/) is a library to get formatted data from web services into python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110553af-fab4-4159-9512-be796409d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonapi_client import Session as APISession\n",
    "from jsonapi_client import Modifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4e633-63a6-4b4f-968a-583c172448b5",
   "metadata": {},
   "source": [
    "--- \n",
    "# API Discovery\n",
    "\n",
    "First, we will learn how to discover and use the API Endpoints (URLs) from the MGnify website.\n",
    "\n",
    "## When the API endpoint is directly mentioned\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "A task for you\n",
    "</div>\n",
    "\n",
    "- Go to [Study MGYS00002008](https://www.ebi.ac.uk/metagenomics/studies/MGYS00002008) on the MGnify website\n",
    "- Scroll down to the \"Programmatic access\" box\n",
    "- Find the \"API endpoint\" value\n",
    "- Click that API endpoint link, you'll see structured data – this is a JSON object\n",
    "- Back on the Study page, copy that API endpoint value\n",
    "- **See if you can complete the following code cell, which will read in that JSON data into Python...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573b529-30f9-4148-ae72-659027ac369c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_endpoint = 'https://_______________________________________'\n",
    "\n",
    "api_response = requests.get(api_endpoint)\n",
    "api_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b2e44-23d3-43fe-afb8-5a37cb9909a8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Unhide the cell below (click the •••) to see or use the answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631662a-cec9-4796-9233-a18941db019e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_endpoint = 'https://www.ebi.ac.uk/metagenomics/api/v1/studies/MGYS00002008'\n",
    "\n",
    "api_response = requests.get(api_endpoint)\n",
    "api_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea0ff5-fd8b-4cb0-9bff-2c6f56f24968",
   "metadata": {},
   "source": [
    "Notice that this is now a Python dictionary of `data`, with some generic sounding top-level keys like `attributes` and `relationships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268fef6-df9a-4350-9bc8-4a2fb74b5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response.json()['data'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bd460-b2b2-4dfa-8a8e-c9000d6f5bb2",
   "metadata": {},
   "source": [
    "These are part of the JSON:API specification that makes the API even easier to use with code libraries... More on that in a moment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d002f-4cfe-4691-96dd-0ee6f41077dd",
   "metadata": {},
   "source": [
    "## From the Browsable API root\n",
    "Usually, you'll need to find a starting point for your API request endpoint.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "A task for you\n",
    "</div>\n",
    "\n",
    "- Browse to https://www.ebi.ac.uk/metagenomics/api/v1\n",
    "- Notice that there are lots of API routes listed here, for all kind of MGnify datasets\n",
    "- Click on the `\"studies\"` endpoint\n",
    "- How would you find the MGYS00002008 endpoint from here?\n",
    "    - Click the \"Filters\" button near the top.\n",
    "    - Type `MGYS00002008` into the first filter (for an accession)\n",
    "    - Click Submit\n",
    "- Notice you're now on an API view which **lists** studies matching your query. There is only one, exactly matching your query, but it is still a list.\n",
    "- Find (by eye) the URL keyed by `data[0].links.self`.\n",
    "- Is this the same URL as the API Endpoint you copied from the website study page? (__It should be!__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59a5a4-b320-4a07-9e69-2bc0e5b23002",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When you're after more than one database entry\n",
    "\n",
    "More realistically, you will run API queries that return many results.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "A task for you\n",
    "</div>\n",
    "\n",
    "- Browse back to the [API Studies list endpoint](https://www.ebi.ac.uk/metagenomics/api/v1/studies)\n",
    "- Use the Filter button to limit the query to Studies from the `root:Host-associated:Insecta` biome lineage \n",
    "- The returned dataset is long... **but is it all of the matching Studies?**\n",
    "    - Check the `links` section of data... or the `meta.pagination` section of data (probably right at the bottom).\n",
    "    \n",
    "- To get **all** of the matching data, we need to make multiple requests - one for each page of data\n",
    "\n",
    "### Fetching paginated datasets\n",
    "This quickly gets complicated, but the `jsonapi_client` library can make it easy! It `iterate`s over the pages for us...\n",
    "\n",
    "**Try and complete this code cell to read all `root:Host-associated:Insecta` studies into a Pandas dataframe (like a table)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c72da8-68a3-4819-b3d0-8ca6e671adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"studies\"\n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    biome_filter = Modifier(\"lineage=root:______________________________\")\n",
    "    resources = map(lambda r: r.json, mgnify.iterate(endpoint_name, filter=biome_filter))\n",
    "    resources = pd.json_normalize(resources)\n",
    "resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0234a-8813-4074-9c30-6004691f1e79",
   "metadata": {},
   "source": [
    "If you know Pandas well... how would you write that table of studies into a CSV file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e5b58-4cac-4d00-8dc7-65323a6673a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hint: there is a Pandas dataframe method to do exactly this!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f3f44-d008-44cf-928c-810c59df3a90",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Unhide the cell below (click the •••) to see or use the answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603ae8e-5e38-4cbd-8145-3926737e86d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"studies\"\n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    biome_filter = Modifier(\"lineage=root:Host-associated:Insecta\")\n",
    "    resources = map(lambda r: r.json, mgnify.iterate(endpoint_name, filter=biome_filter))\n",
    "    resources = pd.json_normalize(resources)\n",
    "resources.to_csv(f\"insecta_studies.csv\")\n",
    "resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d42d24-b5b0-43e9-93ca-352fb75e0ac5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Line by line explanation\n",
    "\n",
    "```python\n",
    "### The packages were already imported, but if you wanted to use this snippet on it's own as a script you would import them like this:\n",
    "from jsonapi_client import Session as APISession\n",
    "import pandas as pd\n",
    "###\n",
    "\n",
    "\n",
    "endpoint_name = 'studies'\n",
    "# An \"endpoint\" is the specific resource within the API which we want to get data from. \n",
    "# It is the a URL relative to the \"server base URL\" of the API, which for MGnify is https://www.ebi.ac.uk/metagenomics/api/v1.\n",
    "# You can find the endpoints in the API Docs https://www.ebi.ac.uk/metagenomics/api/docs/ \n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    # Calling \"APISession\" is enabling a connection to the MGnify API, that can be used multiple times. \n",
    "    # The `with...as mgnify` syntax is a Python \"context\". \n",
    "    # Everything inside the `with...` block (i.e. indented below it) can use the `APISession` which we've called `mgnify` here. \n",
    "    # When the `with` block closes (the indentation stops), the connection to the API is nicely cleaned up for us.\n",
    "    \n",
    "    # Using a Modifier, we can filter the results from the API. \n",
    "    # The biome_filter will add the \"lineage=XXX\" to the query sent to the API\n",
    "    # This will be used by the API to filter the studies in the response by the biome specified in \"lineage\"\n",
    "    biome_filter = Modifier(\"lineage=root:Host-associated:Insecta\")\n",
    "\n",
    "    resources = map(lambda r: r.json, mgnify.iterate(endpoint_name, filter=biome_filter))\n",
    "    # `map` applies a function to every element of an iterable - so do something to each thing in a list.\n",
    "    # Remember we said the API is paginated? \n",
    "    # `mgnify.iterate(endpoint_name)` is a very helpful function that loops over as many pages of results as there are.\n",
    "    # `lambda r: r.json` is grabbing the JSON attribute from each Super Study returned from the API.\n",
    "    # All together, this makes `resources` be a bunch of JSON representations we could loop through, each containing the data of a Super Study.\n",
    "    \n",
    "    resources = pd.json_normalize(resources)\n",
    "    # `pd` is the de-facto shorthand for the `pandas` package - you'll see it anywhere people are using pandas.\n",
    "    # The `json_normalize` function takes \"nested\" data and does its best to turn it into a table.\n",
    "    # You can throw quite strange-looking data at it and it usually does something sensible.\n",
    "    \n",
    "    resources.to_csv(f\"{endpoint_name}.csv\")\n",
    "    # Pandas has a built-in way of writing CSV (or TSV, etc) files, which is helpful for getting data into other tools.\n",
    "    # This writes the table-ified Super Study list to a file called `super-studies.csv`.\n",
    "    \n",
    "resources\n",
    "# In a Jupyter notebook, you can just write a variable name in a cell (or the last line of a long cell), and it will print it.\n",
    "# Jupyter knows how to display Pandas tables (actually called \"DataFrames\", because they are More Than Just Tables ™) in a pretty way.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df4b49-7bf0-4869-bf1b-05fd64e075ca",
   "metadata": {},
   "source": [
    "--- \n",
    "# MAGs resources - programmatically\n",
    "\n",
    "## Listing genomic resources from the MGnify API\n",
    "\n",
    "**The goals of this task are to make a genus-specific version of [Extended Data Figure 4a from Almeida et al 2020](https://www.nature.com/articles/s41587-020-0603-3/figures/10), as well as to see which biomes that genus is present in**\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "A task for you\n",
    "</div>\n",
    "\n",
    "- Write some Python code that fetches all MGnify genomes from the `Streptococcus` genus into a Pandas Dataframe.\n",
    "- Make a \"Box and whiskers\" plot of the Completeness and Contamination distributions for the genomes in that genus.\n",
    "- Make a histogram plot showing how many times this genus appears in each biome-specifc catalogue\n",
    "\n",
    "Hints:\n",
    "- The lineage for the Streptococcus genus is `d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Streptococcaceae;g__Streptococcus`\n",
    "- The [API endpoint name for genomes is `genomes`](https://www.ebi.ac.uk/metagenomics/api/v1/genomes)\n",
    "- The API filter key on that endpoint, for taxonomic lineage, is `taxon_lineage=`\n",
    "- The completeness and contamination % values for each genome are in `attributes['completeness']` and `attributes['contamination']` respectively. Pandas normalizes these to columns named `'attributes.completeness'` and `'attributes.contamination'`\n",
    "- There is a [Pandas method `.boxplot`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html) to make a boxplot from a dataframe column/series\n",
    "- The catalogue ID a genome belongs to is in `relationships['catalogue']['data']['id']`, which Pandas normalizes to a column named `relationships.catalogue.data.id`\n",
    "- A column (series) of data from a Pandas dataframe can be selected like `resources['my.column.name']` and the [Pandas `.hist()` method] by default shows a histogram of data counts grouped by unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552b9fb-14fa-479d-acd7-c28eeb0e1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"_______\"\n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    lineage_filter = _________________________\n",
    "    resources = _________________\n",
    "    resources = pd.json_normalize(resources)\n",
    "resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18068bb-a9bd-4293-99fc-918d979875f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_________.boxplot(_________________________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed554a-db1c-4f55-b2df-f5ffdd0aaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "resources['____________________________').hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1c658-12a2-40c9-a7cf-876ced5f5960",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Unhide the cells below (click the •••) to see or use the answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be3663-9ba4-48ac-bae0-d750dd0c1ee7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"genomes\"\n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    lineage_filter = Modifier(\"taxon_lineage=d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Streptococcaceae;g__Streptococcus\")\n",
    "    resources = map(lambda r: r.json, mgnify.iterate(endpoint_name, filter=lineage_filter))\n",
    "    resources = pd.json_normalize(resources)\n",
    "resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34daaee-40c8-4fe7-941f-829a16a8d6fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resources.boxplot(column=['attributes.completeness', 'attributes.contamination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc28d42-9b70-45c4-8f5a-6c72a1d4e4bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resources['relationships.catalogue.data.id'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a66d0-d40b-4694-aa10-efd87e4de1e0",
   "metadata": {},
   "source": [
    "## Find out whether your own MAGs are novel compared to the MGnify catalogues\n",
    "\n",
    "**The goal of this task is to query your own MAGs (created on course day 3) against MGnify's MAG catalogues, to see whether they are novel or already represented**\n",
    "\n",
    "Your MAGs generated on Day 3 should be in the directory `/home/training/Binning/contigs.fasta.metabat-bins2000.bak`. If something went wrong on Day 3 and you don't have those files any more, there are backup ones you can copy from `/media/penelopeprime/genome-resolved-metagenomics-2022/contigs.fasta.metabat-bins2000.bak`\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "A task for you\n",
    "</div>\n",
    "\n",
    "- Query the MGnify API to get a list of the IDs of all Genome Catalougues (using `jsonapi_client` as before)\n",
    "- Use the `sourmash` package to create a \"sketch\" of each of your MAGs\n",
    "- Using the `requests` library (we used this before in <a href=\"#When-the-API-endpoint-is-directly-mentioned\">the first task</a>), send your sketches to the MGnify Genome Search API with a `POST` request\n",
    "- Check the progress of your search job in a loop that waits for it to finish\n",
    "- Build a Pandas Dataframe with the search results for all of your MAGs\n",
    "\n",
    "This task involves lots of new ideas, so a lot of the code is written for you. Rather than writing the code, try and understand what each step is doing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7462e7ef-5129-4c45-9669-0fe5a38787fe",
   "metadata": {},
   "source": [
    "### Fetch all of the catalogue IDs currently available on MGnify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ac671-6592-4fdf-afe2-8ff644a088ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"genome-catalogues\"\n",
    "\n",
    "with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    resources = map(lambda r: r.json, mgnify.iterate(endpoint_name))\n",
    "    resources = pd.json_normalize(resources)\n",
    "resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103621c-2a00-461e-be5c-f1243bdadfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogues = list(resources['id'])\n",
    "catalogues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead19559-86f3-4fef-b0be-98cafb7818b0",
   "metadata": {},
   "source": [
    "### Find all of our own MAGs, and create [\"sketches\" of them using Sourmash](https://sourmash.readthedocs.io/en/latest/index.html#sourmash-in-brief)\n",
    "We’ll compute a sourmash sketch for each MAG. A sketch goes into a signature, that we will use for searching. The signature is a sort of collection of hashes that are well suited for calculating the *containment* of your MAGs within the catalogue's MAGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efcefc8-df9c-432f-93fd-3b3b1d1c3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sourmash\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a860106e-d915-4077-b880-923b3871d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_mags_folder = Path('/home/training/Binning/contigs.fasta.metabat-bins2000.bak')\n",
    "my_mags_folder = Path('/Users/sandyr/Downloads/contigs.fasta.metabat-bins2000.bak/')\n",
    "\n",
    "# pathlib is a handy standard Python library for finding files and directories\n",
    "my_mags_files = list(my_mags_folder.glob('*.fa*'))\n",
    "my_mags_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac471e-8b36-4ff9-8326-e10de915ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mag_file in my_mags_files:\n",
    "    # the sourmash parameters are chosen to match those used within MGnify\n",
    "    sketch = sourmash.MinHash(n=0, ksize=31, scaled=1000)\n",
    "    \n",
    "    # a fasta file may have multiple records in it. add them all to the sourmash signature.\n",
    "    for index, record in enumerate(SeqIO.parse(mag_file, 'fasta')):\n",
    "        sketch.add_sequence(str(record.seq))\n",
    "\n",
    "    # save the sourmash sketch as a \"signature\" file\n",
    "    sig = sourmash.SourmashSignature(sketch, name=record.name or mag_file.stem)\n",
    "    with open(mag_file.stem + '.sig', 'wt') as fp:\n",
    "        sourmash.save_signatures([sig], fp)\n",
    "\n",
    "# check what signature files we've created.\n",
    "# using ! in Jupyter lets you run a shell command. It is handy for quick things like pwd and ls.\n",
    "!ls *.sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eec4eb-66ed-438c-819c-fdfd731bceed",
   "metadata": {},
   "source": [
    "### Submit a search job to the MGnify API\n",
    "We’ll call the MGnify API with all of our sketches.\n",
    "There is an endpoint for this (the same one used by the website).\n",
    "\n",
    "In this case, we need to **send** data to the API (not just fetch it). This is called \"POST\"ing data in the API world. \n",
    "\n",
    "This part of the API is quite specialized and so is not a formal JSON:API, so we use the more flexible [requests](https://docs.python-requests.org/en/master/) Python package to communicate with it, like we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b3f7e-2c44-409d-9804-4eb508d35713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb14b28-d362-4908-985a-380803ecc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://www.ebi.ac.uk/metagenomics/api/v1/genomes-search/gather'\n",
    "\n",
    "# Create a list of file uploads, and attach them to the API request\n",
    "signatures = [open(mag.stem + '.sig', 'rb') for mag in my_mags_files]\n",
    "sketch_uploads = [('file_uploaded', signature) for signature in signatures]\n",
    "\n",
    "# Send the API request - it specifies which catalogue to search against and attaches all of the signature files.\n",
    "submitted_job = requests.post(endpoint, data={'mag_catalogues': catalogues}, files=sketch_uploads).json()\n",
    "\n",
    "map(lambda fp: fp.close(), signatures)  # tidy up open file pointers\n",
    "\n",
    "print(submitted_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e681b1-8fef-4deb-b349-0ca0d23f7646",
   "metadata": {},
   "source": [
    "### Wait for our results to be ready\n",
    "\n",
    "As you can see in the printed `submitted_job` above, a `status_URL` was returned in the response from submitting the job via the API.\n",
    "Since the job will be in a queue, we must poll this `status_URL` to wait for our job to be completed.\n",
    "We’ll check every 2 seconds until ALL of the jobs are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf13cb7-f5d2-49ba-9a3c-6b5c5027f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_done = False\n",
    "while not job_done:\n",
    "    print('Checking status...')\n",
    "    status = requests.get(submitted_job['data']['status_URL'])\n",
    "    # the status_URL is just another API endpoint that's unique for our search job\n",
    "    \n",
    "    queries_done = {sig['job_id']: sig['status'] for sig in status.json()['data']['signatures']}\n",
    "    job_done = all(map(lambda q: q == 'SUCCESS', queries_done.values()))\n",
    "    if not job_done:\n",
    "        print('Still waiting for jobs to complete. Current status of jobs')\n",
    "        print(queries_done)\n",
    "        print('Will check again in 2 seconds')\n",
    "        time.sleep(2)\n",
    "\n",
    "print('All finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb7b2e-1e44-45fa-a677-fa2a5d74b33a",
   "metadata": {},
   "source": [
    "You can inspect the JSON data we got back by typing `status.json()` into a code cell... But essentially we have a result for each MAG against each catalogue, possibly including a best match MAG (if there was one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9625373-ca55-4c40-849c-12437a64eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = pd.json_normalize(status.json()['data']['signatures'])\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfecaab1-aea2-41fd-b14e-b5aea825fdbd",
   "metadata": {},
   "source": [
    "### Are any of our MAGs found in biomes other than the human gut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736ae13-866e-43f7-969f-1ce7ab50cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = search_results.dropna(subset=['result.match'])\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b424059-019a-4fdb-8e50-323151f7147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.catalogue.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4dc33-6456-40a0-9126-254f1b99c5ee",
   "metadata": {},
   "source": [
    "### What is the taxonomy of the MGnify MAGs which match our query MAGs?\n",
    "To find this, we can call the API for each Genome, to find it's taxonomic lineage... We can put these results into a new column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6fbb0-064d-47d8-80fb-4ee2981162ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxonomy_of_mgnify_mag(match_row):\n",
    "    mgyg_accession = match_row['result.match']\n",
    "    with APISession(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "        genome_document = mgnify.get('genomes', mgyg_accession)\n",
    "        return genome_document.resource.taxon_lineage\n",
    "    \n",
    "matches['best_match_taxonomy'] = matches.apply(get_taxonomy_of_mgnify_mag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14789d3c-e464-49d2-ae8d-70ffd8dc872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, match in matches.iterrows():\n",
    "    print(f\"My MAG {match['filename']} matches {match['result.match']} which has taxonomy {match['best_match_taxonomy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af8846-2fd7-4684-ac55-9bc54ce22eaa",
   "metadata": {},
   "source": [
    "### Which of our MAGs are completely novel (i.e. in no MGnify catalogue)?\n",
    "\n",
    "One way to check this is group all of the search results by filename (i.e. finding the queries for each MAG vs all catalogues) and checking whether the sum of all matches is 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a976c1-21bb-492a-9bfc-daf4b6a6ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.groupby('filename').apply(lambda query: query['result.matches'].sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8913a-bb94-4aa6-9235-e029fb1178a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2e909ea68d00cf590af4aa2de30821786e45b8e11ea607135c2643544907b22"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
